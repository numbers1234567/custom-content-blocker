{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from BLIP/blip_base.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_checkpoints/blip_nlvr/blip_nlvr_mlp_e5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLIP NLVR\n",
    "import sys\n",
    "sys.path.append(\"BLIP\")\n",
    "from pipelines_train import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "classifier = BLIPClassifier(BLIPNLVRHead(med_config=\"BLIP/configs/med_config.json\", device=device, dropout=True), med_config=\"BLIP/configs/med_config.json\", pretrain_path=\"BLIP/blip_base.pth\", device=device, text_inject=True)\n",
    "\n",
    "blip_img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((blip_img_size,blip_img_size),interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "val_transform = train_transform\n",
    "\n",
    "def save_path(i):\n",
    "    return f\"model_checkpoints/blip_nlvr/blip_nlvr_mlp_e{i}\"\n",
    "save_path(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from BLIP/blip_base.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_checkpoints/blip_deep_mlp_1/blip_deep_mlp_1_e5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLIP w/ CLS Head\n",
    "import sys\n",
    "sys.path.append(\"BLIP\")\n",
    "from pipelines_train import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "classifier = BLIPClassifier(BLIPDeepHead1(med_config=\"BLIP/configs/med_config.json\", device=device), med_config=\"BLIP/configs/med_config.json\", pretrain_path=\"BLIP/blip_base.pth\", device=device, text_inject=True)\n",
    "\n",
    "blip_img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((blip_img_size,blip_img_size),interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "val_transform = train_transform\n",
    "\n",
    "def save_path(i):\n",
    "    return f\"model_checkpoints/blip_deep_mlp_1/blip_deep_mlp_1_e{i}\"\n",
    "save_path(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from BLIP/blip_base.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_checkpoints/blip_deep_mlp_2/blip_deep_mlp_2_e5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLIP w/ CLS Head\n",
    "import sys\n",
    "sys.path.append(\"BLIP\")\n",
    "from pipelines_train import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "classifier = BLIPClassifier(BLIPDeepHead2(med_config=\"BLIP/configs/med_config.json\", device=device), med_config=\"BLIP/configs/med_config.json\", pretrain_path=\"BLIP/blip_base.pth\", device=device, text_inject=True)\n",
    "\n",
    "blip_img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((blip_img_size,blip_img_size),interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "val_transform = train_transform\n",
    "\n",
    "def save_path(i):\n",
    "    return f\"model_checkpoints/blip_deep_mlp_2/blip_deep_mlp_2_e{i}\"\n",
    "save_path(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from BLIP/blip_base.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_checkpoints/blip_deep_mlp_3/blip_deep_mlp_3_e5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLIP w/ CLS Head\n",
    "import sys\n",
    "sys.path.append(\"BLIP\")\n",
    "from pipelines_train import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "classifier = BLIPClassifier(BLIPDeepHead3(med_config=\"BLIP/configs/med_config.json\", device=device, dropout=True), med_config=\"BLIP/configs/med_config.json\", pretrain_path=\"BLIP/blip_base.pth\", device=device, text_inject=True)\n",
    "\n",
    "blip_img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((blip_img_size,blip_img_size),interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "val_transform = train_transform\n",
    "\n",
    "def save_path(i):\n",
    "    return f\"model_checkpoints/blip_deep_mlp_3/blip_deep_mlp_3_e{i}\"\n",
    "save_path(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLIP w/ SVM Head\n",
    "import sys\n",
    "sys.path.append(\"BLIP\")\n",
    "from pipelines_train import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "classifier = BLIPClassifier(BLIPSVMHead(), med_config=\"BLIP/configs/med_config.json\", pretrain_path=\"BLIP/blip_base.pth\", device=device)\n",
    "\n",
    "blip_img_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((blip_img_size,blip_img_size),interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "val_transform = train_transform\n",
    "\n",
    "def save_path(i):\n",
    "    return f\"model_checkpoints/blip_svm/blip_svm\"\n",
    "save_path(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RedditData import *\n",
    "\n",
    "main_csv_path = \"../datasets/main_val_0.8_0.1.csv\"\n",
    "\n",
    "train_dataset = RedditDataset(\"../datasets\", main_csv=main_csv_path, im_transform=train_transform)\n",
    "train_sampler = RedditDataSampler(\"../datasets\", main_csv=main_csv_path, upsampling=True)\n",
    "\n",
    "val_dataset = RedditDataset(\"../datasets\", main_csv=main_csv_path, split=\"valid\", im_transform=val_transform)\n",
    "val_sampler = RedditDataSampler(\"../datasets\", main_csv=main_csv_path, split=\"valid\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_sampler=BatchSampler(train_sampler, batch_size, True))\n",
    "val_dataloader = DataLoader(val_dataset, batch_sampler=BatchSampler(val_sampler, 1, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "def validation(classifier, val_dataloader):\n",
    "    loss = CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        loss_val = 0\n",
    "        n = len(val_dataloader)\n",
    "        for i in val_dataloader:\n",
    "            text,image,label,has_image = i\n",
    "            image = image.float()\n",
    "            label = F.one_hot(label, num_classes=2).float()\n",
    "            loss_val += loss(torch.from_numpy(classifier(image, text, has_image)).float(), label).item()/n\n",
    "\n",
    "        return loss_val\n",
    "    \n",
    "#validation(classifier, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss - 0.635244: 100%|██████████| 103/103 [04:25<00:00,  2.57s/it]\n",
      "Validation loss - 0.693871: 100%|██████████| 103/103 [04:27<00:00,  2.59s/it]\n",
      "Validation loss - 0.579983: 100%|██████████| 103/103 [04:35<00:00,  2.68s/it]\n",
      "Validation loss - 0.550179: 100%|██████████| 103/103 [04:17<00:00,  2.50s/it]\n",
      "Validation loss - 0.692487: 100%|██████████| 103/103 [03:48<00:00,  2.22s/it]\n",
      "Validation loss - 0.503549: 100%|██████████| 103/103 [03:47<00:00,  2.21s/it]\n",
      "Validation loss - 0.550018: 100%|██████████| 103/103 [03:46<00:00,  2.20s/it]\n",
      "Validation loss - 0.608224: 100%|██████████| 103/103 [03:44<00:00,  2.18s/it]\n",
      "Validation loss - 0.638812: 100%|██████████| 103/103 [03:43<00:00,  2.17s/it]\n",
      "Validation loss - 0.595449: 100%|██████████| 103/103 [03:44<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(10):\n",
    "    pbar = tqdm(train_dataloader, \"Loss - \")\n",
    "    for idx,data in enumerate(pbar):\n",
    "        text,image,label,has_image = data\n",
    "        image = image.float()\n",
    "        label = F.one_hot(label, num_classes=2).float()\n",
    "        classifier.train(image,text,label,has_image)\n",
    "        if idx==len(pbar)-1:\n",
    "            pbar.set_description(\"Validation loss - %f\" % (validation(classifier, val_dataloader)))\n",
    "    classifier.save(save_path(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      2\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mload(save_path(i))\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m, in \u001b[0;36mvalidation\u001b[1;34m(classifier, val_dataloader)\u001b[0m\n\u001b[0;32m      6\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_dataloader)\n\u001b[1;32m----> 8\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhas_image\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\angel\\anaconda3\\envs\\custom_content_blocker\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\angel\\anaconda3\\envs\\custom_content_blocker\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\angel\\anaconda3\\envs\\custom_content_blocker\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\angel\\anaconda3\\envs\\custom_content_blocker\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\angel\\Documents\\GitHub\\custom-content-blocker\\evaluation\\RedditData.py:39\u001b[0m, in \u001b[0;36mRedditDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     36\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedia_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedia_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mindex][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     37\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m image_paths]\n\u001b[1;32m---> 39\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     40\u001b[0m images \u001b[38;5;241m=\u001b[39m [im \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m images \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     42\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\angel\\Documents\\GitHub\\custom-content-blocker\\evaluation\\RedditData.py:39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedia_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedia_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mindex][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     37\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m image_paths]\n\u001b[1;32m---> 39\u001b[0m images \u001b[38;5;241m=\u001b[39m [\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m image_paths][\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     40\u001b[0m images \u001b[38;5;241m=\u001b[39m [im \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m images \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     42\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\angel\\anaconda3\\envs\\custom_content_blocker\\Lib\\site-packages\\PIL\\Image.py:922\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m    876\u001b[0m ):\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 922\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\angel\\anaconda3\\envs\\custom_content_blocker\\Lib\\site-packages\\PIL\\ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    classifier.load(save_path(i))\n",
    "    print(validation(classifier, val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_output(classifier, dataloader):\n",
    "    ret = []\n",
    "    for batch in dataloader:\n",
    "        text,image,label,has_image = batch\n",
    "        image = image.float()\n",
    "        yp = classifier(image,text,has_image)\n",
    "        for i in range(len(text)):\n",
    "            ret.append(((text[i],image[i].cpu().detach().numpy(),label[i].cpu().detach().numpy(),has_image[i].cpu().detach().numpy()),yp[i]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "def get_failure_cases(model_out, thresh=0.5):\n",
    "    idx = []\n",
    "    for i in range(len(model_out)):\n",
    "        (text,image,label,has_image),pred = model_out[i]\n",
    "        gt = label\n",
    "        ans = 1 if pred[1] >= thresh else 0\n",
    "        if ans != gt: idx.append(i)\n",
    "    return idx\n",
    "\n",
    "def get_metrics(model_out):\n",
    "    scores = [i[1][1] for i in model_out]\n",
    "    roc=roc_curve([i[0][2] for i in model_out], scores)\n",
    "    auc = roc_auc_score([i[0][2] for i in model_out], scores)\n",
    "    num1 = sum([i[0][2] for i in model_out])\n",
    "    num0 = len(model_out) - num1\n",
    "    fp = sum([1 if i[0][2]==0 and np.round(i[1][1])==1 else 0 for i in model_out])\n",
    "    fn = sum([1 if i[0][2]==1 and np.round(i[1][1])==0 else 0 for i in model_out])\n",
    "    tp = sum([1 if i[0][2]==1 and np.round(i[1][1])==1 else 0 for i in model_out])\n",
    "    tn = sum([1 if i[0][2]==0 and np.round(i[1][1])==0 else 0 for i in model_out])\n",
    "    correct = sum([1 if i[0][2]==np.round(i[1][1]) else 0 for i in model_out])\n",
    "    return roc,auc,fp,fn,tp,tn,num0,num1,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load(save_path(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_checkpoints/blip_deep_mlp_3/blip_deep_mlp_3_e0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = get_val_output(classifier, val_dataloader)\n",
    "roc,auc,fp,fn,tp,tn,num0,num1,correct = get_metrics(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thresh = roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7913366336633664, 65, 152, 748, 137, 202, 900, 885)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc,fp,fn,tp,tn,num0,num1,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x243aba17c50>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails = get_failure_cases(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([model_out[fail][0][2] for fail in fails])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=14\n",
    "(text,image,label,has_image),yp = model_out[i]\n",
    "text,label,has_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im = np.transpose(image, (1,2,0))\n",
    "\n",
    "plt.imshow(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_content_blocker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
